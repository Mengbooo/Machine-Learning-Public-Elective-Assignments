任务描述
实现一个MLP分类模型，训练多层神经网络，对于手写数字图像进行分类。

完成模型前向传播(forward)函数。
完成模型训练(fit)函数。
相关知识
MLP
多层感知机（Multilayer Perceptron, MLP）是一种前馈人工神经网络，是深度学习中的基础模型之一。它由多个层次的神经元（或节点）组成，包括输入层、一个或多个隐藏层以及输出层，每一层中的神经元与下一层的神经元全连接。



每个隐藏层的神经元通常使用非线性激活函数，如ReLU（Rectified Linear Unit）、Sigmoid或Tanh，引入非线性能力，使网络能够学习复杂的模式。



多层感知机（MLP）的训练过程涉及将输入数据送入网络中进行前向传播，得到预测值后，计算其与实际标签的真实值之间的损失；随后通过反向传播算法计算损失相对于每个参数的梯度，并使用如梯度下降等优化方法来更新这些参数，以此逐步减少损失，直至模型收敛或达到预定的训练周期结束。

前向传播
多层感知器（MLP）的前向传播过程可以分为多个层次进行，每一层的计算可以表示为：

输入层到隐藏层的计算：
[z 
(1)
 =W 
(1)
 x+b 
(1)
 ]

[a 
(1)
 =f(z 
(1)
 )]

隐藏层到下一个隐藏层的计算（如果有多层隐藏层，则重复以下步骤）：
[z 
(n)
 =W 
(n)
 a 
(n−1)
 +b 
(n)
 ]

[a 
(n)
 =f(z 
(n)
 )]

最后一层（输出层）的计算：
[z 
(N)
 =W 
(N)
 a 
(N−1)
 +b 
(N)
 ]

[a 
(L)
 =f 
output
​
 (z 
(N)
 )]

在这些公式中：

x是输入向量。
W 
(l)
 和 b 
(l)
  分别是第 l 层的权重矩阵和偏置向量。
z 
(l)
 是第 l层的线性变换输出。
a 
(l)
 是第 l 层的激活输出。
f 是隐藏层的激活函数（例如ReLU、Sigmoid、Tanh等）。
f 
output
​
  是输出层的激活函数（例如Softmax用于分类问题，线性激活用于回归问题）。
通过这些步骤，MLP可以将输入数据通过多个非线性变换映射到输出。

相关函数
np.dot(x,y): 內积运算，即元素之间先算乘法再相加。若x,y是向量，计算得到一个数值；若x,y是矩阵，计算得到一个向量;

relu(x): 返回向量x经过relu后的计算结果；

softmax(x): 返回向量x经过softmax后的计算结果；

cross_entropy_loss(y_pred,y): 计算y_pred和y向量之间的交叉熵损损失。

编程要求
根据提示，在右侧编辑器中完善代码，平台会对模型的实现和功能进行评估

测试说明
本关占期末总成绩的2.5分，其中编译通过不返回错误获得0.5分，模型测试分类精度≥0.65获得2分。若程序逻辑大致正确但编译未通过获得1分。
（训练过程大约30秒，请同学们耐心等待；由于训练时间的限制，模型未完全收敛，每次测试结果会存在波动）